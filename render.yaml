# Render Deployment Configuration for InferenceMD
# Defines the services needed to run the application on Render.
# Documentation: https://render.com/docs/blueprint-spec

databases:
  # Database service for the FastAPI backend
  - name: inferencemd-db
    # region: frankfurt # Optional: Choose a region close to you/your users
    plan: free # Or choose a paid plan for production needs
    postgresMajorVersion: 14 # Specify PostgreSQL version
    ipAllowList: [] # Allows connections from Render services by default

services:
  # Backend Web Service (FastAPI)
  # Runs the Python backend application using the Dockerfile.
  - type: web
    name: inferencemd-backend
    # Reverted to Docker runtime
    runtime: docker 
    plan: free
    # Docker build settings
    dockerfilePath: ./backend/Dockerfile 
    dockerContext: ./backend 
    # Command to run migrations and start the server inside the container
    startCommand: "alembic upgrade head && gunicorn -w 4 -k uvicorn.workers.UvicornWorker app.main:app" 
    healthCheckPath: / # Use the root path for health checks
    envVars:
      # Database and Core Settings
      - key: DATABASE_URL
        fromDatabase:
          name: inferencemd-db
          property: connectionString
      - key: SECRET_KEY
        generateValue: true
      - key: PYTHON_VERSION
        value: "3.10.13" 
      # PYTHONPATH is handled by Dockerfile WORKDIR/ENV
      # CORS_ORIGINS will be constructed in config.py using RENDER_FRONTEND_URL
      - key: RENDER_FRONTEND_URL # Variable to hold the raw URL from Render
        fromService:
          type: web
          name: inferencemd-frontend
          property: url # Get the full URL string
      
      # LLM Provider Configuration
      # Set this to one of: "azure", "openai", "gemini", "deepseek"
      - key: LLM_PROVIDER
        value: "gemini"
      
      # Google Gemini Settings (when LLM_PROVIDER="gemini")
      # IMPORTANT: Store sensitive keys like API keys as Render Secret Files or in Environment Groups
      # See: https://render.com/docs/configure-environment-variables#secret-files
      # Example using a secret key named 'google_api_key':
      - key: GOOGLE_API_KEY
        fromSecretKeyRef:
          name: google_api_key # Name of the secret key you create in Render dashboard
          key: GOOGLE_API_KEY # The specific key within the secret (if using env group)
      - key: LLM_MODEL_NAME
        value: gemini-2.5-pro-preview-03-25 # Example: Use a specific model version
      
      # Common LLM Parameters (apply to all providers)
      - key: LLM_TEMPERATURE
        value: "0.5"
      - key: LLM_MAX_TOKENS
        value: "4096"
      - key: LLM_TIMEOUT
        value: "120"
      - key: LLM_MAX_RETRIES
        value: "2"
      
      # File Storage Settings
      - key: REPORTS_DIR
        value: "/tmp/reports"
      - key: NOTES_DIR
        value: "/tmp/notes"
      - key: STATIC_DIR
        # Path inside the Docker container
        value: "/app/static" 
    # Removed native Python runtime fields (pythonVersion, buildCommand)

  # Frontend Static Site (React)
  - type: web
    name: inferencemd-frontend
    runtime: static
    # Ensure frontend build command still works relative to repo root
    buildCommand: "cd frontend && npm ci && npm run build"
    staticPublishPath: ./frontend/build
    envVars:
      - key: CI
        value: "false"
      - key: NODE_VERSION
        value: "18"
      - key: REACT_APP_API_BASE_URL
        fromService:
          type: web
          name: inferencemd-backend
          property: host
    routes:
      - type: rewrite
        source: /*
        destination: /index.html
